# Artificial-Intelligence---Attention-based-NLP

# ðŸ“Œ Overview

This project implements a basic but functional Question-Answering (QA) model using:

âœ… Encoder-Decoder architecture

âœ… Bahdanau Attention mechanism

âœ… Teacher Forcing during training

âœ… Gradient Clipping & Learning Rate Scheduling for optimization

âœ… TensorFlow 2.x Custom Models

âœ… Saved model weights & tokenizers for inference

âœ… Interactive CLI interface to chat with the trained model

Perfect for learning, prototyping, or extending into more advanced NLP systems.